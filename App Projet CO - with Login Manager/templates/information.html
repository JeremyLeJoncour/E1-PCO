{% extends 'base.html' %}
{% block content %}
<div class="login_user"><p><img width="27" height="27" style="filter: invert(100%); margin-right:10px" src="/static/images/person-circle.svg">
    {{user}} <a class="to_login" href="/logout" style="margin-left:20px">Déconnexion</a></p></div>
<div class="content-container">
    <div class="container-fluid">

        <!-- Message principale -->
        <div class="jumbotron">
            <div style="color:#00addc; margin-bottom: 20px;">
            <h1 style="color:#00addc;">Réalisation du Projet</h1>
                <p style="color:#00addc;">Projet Chef-d'Oeuvre pour la Certification Développeur IA</p>
            </div>
            <div style="display:flex; justify-content: space-between; margin-top:35px; padding-bottom:30px; border-bottom:solid 2px #2d435c6c">
                <div>
                    <h4 style="color:#00addc; margin-bottom: 30px;">Analyses et Conception du Dataset</h4>
                    <div style="display: flex;">
                        <div>
                            <p>
                                Les jeux de données proviennent d'une <a href="https://www.kaggle.com/c/kkbox-churn-prediction-challenge ">compétition Kaggle</a>
                                présentant de nombreux fichiers CSV d'entrainement et fichiers de soumissions.
                                Plusieurs fichiers (Version 2 et 3) sont à disposition comportant des données des utilisateurs jusqu'à 
                                2017. Le but est ici de créer un fichier CSV unique qui sera ensuite intégré dans une base de données 
                                relationnelle type MySQL. Le nombre d'utilisateurs uniques diffère d'un CSV à l'autre et une étude 
                                approfondie sur un Dataset global apporterait des biais dans la proportion d'individus 
                                désabonnés/abonnés. 
                            </p>
                            <p>
                                Ainsi, les études ont été faites individuellement pour chaque CSV <span style="font-style: italic;">Transactions, 
                                Membres, Logs</span> avec un merge de <span style="font-style: italic;">Train</span>. De plus, le nombre d'utilisateur 
                                global sur les CSV <span style="font-style: italic;">Transactions et Logs</span> est plus élevé que le nombre d'utilisateur unique, 
                                indiquant un aspect temporel des informations. Dans le cadre de ce projet, seule la dernière en date pour chaque membre sera pris en 
                                compte.
                            </p>
                            <p>
                                L'analyse complète effectuée en amont de la création de modèle est 
                                disponible sur le <a href="https://github.com/JeremyLeJoncour/Projet-CO/blob/main/Analyses/Analyses.ipynb">ici</a>.
                            </p>
                        </div>
                    </div> 
                </div>
            </div>
            <div style="display:flex; justify-content: space-between; margin-top:35px; padding-bottom:30px; border-bottom:solid 2px #2d435c6c">
                <div>
                    <h4 style="color:#00addc; margin-bottom: 30px;">Conception du Modèle</h4>
                    <div>
                        <p>
                            Le Dataset résultant de l’analyse a subi un encodage sur les variables catégorielles et temporelles afin que les algorithmes puissent les traiter durant la phase d’apprentissage. La fonction get_dummies de Pandas convertit les données catégorielles en variables indicatrices. Des variables d’ordre binaire sont donc créées. Pour les dates, celles-ci ont été converties en Integer. Il en résulte au total 90 variables pour 725722 instances (725722 clients uniques).
                            Le Dataset a ensuite été segmenté en 3 parties avec l’outil train_test_split de SKlearn :
                            <ul>
                                <li style="color:#ffffff;"> TRAIN est composé de 70% du jeu de données de départ, utilisé dans 
                                    la phase d’apprentissage des modèles.</li>
                                <li style="color:#ffffff;"> Les 30% restants sont partagés entre le Dataset VALID (80%) et TEST 
                                    (20%). VALID est utilisé dans l’évaluation des modèles entraînés, 
                                    afin d’en vérifier leurs performances à travers les différentes 
                                    métriques précédemment évoquées. Le Dataset TEST est incorporé dans 
                                    une base de données relationnelle, et sera utilisé uniquement dans 
                                    l’application du projet.</li>
                            </ul>
                        </p>
                        <p>
                            Du fait que les classes soient déséquilibrées, le paramètre stratify a été défini sur la variable cible is_churn. Pour conserver éventuellement la partition des données, un random_state a été appliqué. Les variables msno et is_churn ont été enlevées de X_train et X_valid.
                            Les données X_train et X_valid ont ensuite été remises à l’échelle par une standardisation (Standarscaler). La configuration de la standardisation a été sauvegardée dans un fichier Scaler.Joblib pour l’appliquer sur de prochaines nouvelles données (dans le cas des données Test ici).
                        </p>
                        <p>
                            Le modèle final sélectionné est le XGBoost Classfier optimisé traitant 30 variables. Ses scores de performance (en privilégiant principalement le Log Loss) sont les plus élevés parmi les différents modèles évalués. 
                        </p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock %}